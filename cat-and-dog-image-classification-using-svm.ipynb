{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*oB3S5yHHhvougJkPXuc8og.gif)\n",
    "\n",
    "## What is Image classification?\n",
    "Image classification is the process of categorizing and labeling groups of pixels or vectors within an image based on specific rules. The categorization law can be devised using one or more spectral or textural characteristics.\n",
    "\n",
    "##  Different image classification techniques:\n",
    "![](https://raw.githubusercontent.com/everydaycodings/files-for-multiplethings/master/1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dines\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dines\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dines\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dines\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dines\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dines\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached grpcio-1.68.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\dines\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached optree-0.13.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dines\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dines\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/390.3 MB 4.2 MB/s eta 0:01:33\n",
      "   ---------------------------------------- 1.6/390.3 MB 4.2 MB/s eta 0:01:33\n",
      "   ---------------------------------------- 2.9/390.3 MB 5.1 MB/s eta 0:01:17\n",
      "   ---------------------------------------- 4.5/390.3 MB 5.6 MB/s eta 0:01:09\n",
      "    --------------------------------------- 6.6/390.3 MB 6.5 MB/s eta 0:01:00\n",
      "    --------------------------------------- 8.9/390.3 MB 7.3 MB/s eta 0:00:53\n",
      "   - -------------------------------------- 10.5/390.3 MB 7.3 MB/s eta 0:00:52\n",
      "   - -------------------------------------- 14.7/390.3 MB 8.9 MB/s eta 0:00:43\n",
      "   -- ------------------------------------- 19.7/390.3 MB 10.6 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 26.2/390.3 MB 12.6 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 33.6/390.3 MB 14.6 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 41.2/390.3 MB 16.4 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 48.5/390.3 MB 17.7 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 53.0/390.3 MB 17.9 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 58.5/390.3 MB 18.4 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 65.3/390.3 MB 19.3 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 70.5/390.3 MB 19.6 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 75.0/390.3 MB 19.7 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 80.7/390.3 MB 20.1 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 88.9/390.3 MB 20.9 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 96.2/390.3 MB 21.6 MB/s eta 0:00:14\n",
      "   ---------- ---------------------------- 103.8/390.3 MB 22.2 MB/s eta 0:00:13\n",
      "   ----------- --------------------------- 111.1/390.3 MB 22.7 MB/s eta 0:00:13\n",
      "   ----------- --------------------------- 120.1/390.3 MB 23.5 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 127.9/390.3 MB 24.0 MB/s eta 0:00:11\n",
      "   ------------- ------------------------- 135.5/390.3 MB 24.5 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 143.4/390.3 MB 25.0 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 150.5/390.3 MB 25.2 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 158.3/390.3 MB 25.6 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 166.5/390.3 MB 26.1 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 174.3/390.3 MB 26.4 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 176.9/390.3 MB 25.9 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 181.4/390.3 MB 25.8 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 189.3/390.3 MB 26.1 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 194.2/390.3 MB 26.0 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 199.5/390.3 MB 26.0 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 204.5/390.3 MB 25.9 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 209.5/390.3 MB 25.8 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 213.4/390.3 MB 25.6 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 217.3/390.3 MB 25.4 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 221.8/390.3 MB 25.3 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 228.9/390.3 MB 25.4 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 237.0/390.3 MB 25.8 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 244.8/390.3 MB 26.0 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 252.4/390.3 MB 26.2 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 259.5/390.3 MB 26.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 265.6/390.3 MB 27.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 273.7/390.3 MB 29.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 281.5/390.3 MB 30.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 288.9/390.3 MB 30.4 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 298.1/390.3 MB 30.5 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 305.1/390.3 MB 30.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 313.0/390.3 MB 30.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 321.1/390.3 MB 31.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 327.9/390.3 MB 31.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 335.3/390.3 MB 31.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 342.4/390.3 MB 31.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 349.4/390.3 MB 31.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.1/390.3 MB 31.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 357.0/390.3 MB 30.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 362.0/390.3 MB 30.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 368.3/390.3 MB 30.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 374.3/390.3 MB 30.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 378.3/390.3 MB 29.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.0/390.3 MB 29.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  388.2/390.3 MB 29.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 29.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 29.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 29.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 29.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 29.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 29.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.3/390.3 MB 25.5 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.68.1-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.4/4.4 MB 33.0 MB/s eta 0:00:00\n",
      "Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 4.5/26.4 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 11.0/26.4 MB 28.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.7/26.4 MB 33.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 33.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 30.4 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 33.6 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.12.23 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 keras-3.7.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Usefull Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Code Given Below Tells to Computer that I will not be using my Entire GPU power. Just use till maximum of 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the training Data using ImageDataGenerator\n",
    "#### One of the methods to prevent overfitting is to have more data. By this, our model will be exposed to more aspects of data and thus will generalize better. To get more data, either you manually collect data or generate data from the existing data by applying some transformations. The latter method is known as Data Augmentation.\n",
    "\n",
    " - **rescale:** rescaling factor. If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided.\n",
    " - **shear_range:** This is the shear angle in the counter-clockwise direction in degrees.\n",
    " - **zoom_range:** This zooms the image.\n",
    " - **horizontal_flip:** Randomly flips the input image in the horizontal direction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input/cat-and-dog/training_set/training_set/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      3\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m, shear_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m training_set \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../input/cat-and-dog/training_set/training_set/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1138\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1122\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1137\u001b[0m ):\n\u001b[1;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:453\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    452\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    455\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input/cat-and-dog/training_set/training_set/'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "training_set = datagen.flow_from_directory(\n",
    "        \"../input/cat-and-dog/training_set/training_set/\",\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode=\"binary\"\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the test Data using ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen1 = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_set = datagen1.flow_from_directory(\n",
    "        \"../input/cat-and-dog/test_set/test_set\",\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode=\"binary\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing useful models for CNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use a Sequential model\n",
    "\n",
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "A Sequential model is **not appropriate** when:\n",
    "- Your model has multiple inputs or multiple outputs\n",
    "- Any of your layers has multiple inputs or multiple outputs\n",
    "- You need to do layer sharing\n",
    "- You want non-linear topology (e.g. a residual connection, a multi-branch model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Convolution\n",
    "This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well.\n",
    "\n",
    "When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers or None, does not include the sample axis), e.g. `input_shape=(64, 64, 3)` for 64x64 RGB pictures in `data_format=\"channels_last\"`. You can use None when a dimension has variable size.\n",
    "\n",
    "**Arguments Used:**\n",
    "- **filters:** Integer, the dimensionality of the output space.\n",
    "- **padding:** one of \"valid\" or \"same\". \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n",
    "- **kernel_size:** An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window.\n",
    "- **activation:** Activation function to use. If you don't specify anything, no activation is applied.\n",
    "- **strides:** An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3, activation='relu', strides=2, input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Pooling\n",
    "Downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Flattening\n",
    "**Flattens the input. Does not affect the batch size.**\n",
    "\n",
    "**Note:** If inputs are shaped (batch,) without a feature axis, then flattening adds an extra channel dimension and output shape is (batch, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation\n",
    "             ='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing out the summary of the Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the CNN\n",
    "#### Attributes:\n",
    "- **optimizer:** String (name of optimizer) or optimizer instance.\n",
    "- **loss:** Loss function.\n",
    "- **metrics:** List of metrics to be evaluated by the model during training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'hinge', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set\n",
    "#### Attributes:\n",
    "- **x:** Input data\n",
    "- **validation_data:** Data on which to evaluate the loss and any model metrics at the end of each epoch.\n",
    "- **epochs:** Integer. Number of epochs to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=cnn.fit(x = training_set, validation_data = test_set, epochs = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting the Train loss,val loss and train acc, val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "cnn.save('./model_rcat_dog.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the sample image converting the image to an array and predicting the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('../input/cat-and-dog/training_set/training_set/dogs/dog.1023.jpg', target_size = (64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image=test_image/255\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result[0]<0:\n",
    "    print(\"The image classified is cat\")\n",
    "else:\n",
    "    print(\"The image classified is dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "## This was Just a Introduction to Image Classification. In the upcomming Noteboook i will work on more complex real world problems."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 23777,
     "sourceId": 30378,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
